# Final Project
## Part I
Sunday, February 13, 2022

### Outline
**Summary**: ML algorithms have proven to bake in and scale up human and societal biases, failing to provide services to people equally and transparently.

**Reader objective:** As a reader, I want to understand how we introduce biases in ML algorithms so that I can apply techniques and good practices to avoid them.

**Story Arc:**
* Set**up**: Companies have used ML algorithms as a refreshing antidote to overcome the objective interpretation of data in human decisions.
* **Conflict**: these algorithms are exacerbating human and societal biases, and in some cases, they can have terrible consequences for the people they're supposed to serve. 
* **Resolution**: the ML community is creating standards and open-source toolkits to prevent these biases.

<img src="final_project-story-arc.jpg" width="800">
